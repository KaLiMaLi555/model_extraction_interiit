diff --git a/DFAD/DFAD_video.py b/DFAD/DFAD_video.py
index cd1b3c6..77692b4 100644
--- a/DFAD/DFAD_video.py
+++ b/DFAD/DFAD_video.py
@@ -91,7 +91,7 @@ def train(args, teacher, student, generator, device, optimizer, epoch):
             # 'criterion': criterion.state_dict()
         }
 
-        if hp.save:
+        if args.wandb_save:
             save_ckp(checkpoint, epoch, args.checkpoint_path, args.checkpoint_base, args.wandb_save)
         
 
@@ -128,10 +128,10 @@ def main():
     parser.add_argument('--wandb_project', type=str, default="model_extraction")
     parser.add_argument('--wandb_name', type=str)
     parser.add_argument('--wandb_run_id', type=str, default=None)
-    parser.add_argument('--resume', type=int, default=False)
+    parser.add_argument('--wandb_resume', action="store_true")
     parser.add_argument('--wandb_watch', action="store_true")
     parser.add_argument('--checkpoint_base', type=str, default="/content")
-    parser.add_argument('--checkpoint_path', type=str, default="/contnet/checkpoints")
+    parser.add_argument('--checkpoint_path', type=str, default="/gdrive/MyDrive/DFAD_video_ckpts")
     parser.add_argument('--wandb_save', action="store_true")
 
 
@@ -156,7 +156,7 @@ def main():
     if args.model_name == "swin-t":
         print()
         config = "./VST/configs/_base_/models/swin/swin_tiny.py"
-        checkpoint = "./swin_tiny_patch244_window877_kinetics400_1k.pth"
+        checkpoint = "/content/swin_tiny_patch244_window877_kinetics400_1k.pth"
         cfg = Config.fromfile(config)
         teacher = build_model(cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg'))
         load_checkpoint(teacher, checkpoint, map_location=device)
diff --git a/DFAD/utils/wandb_utils.py b/DFAD/utils/wandb_utils.py
index cf62fb1..ad9595c 100644
--- a/DFAD/utils/wandb_utils.py
+++ b/DFAD/utils/wandb_utils.py
@@ -2,7 +2,7 @@ import wandb
 import os
 import numpy as np
 from sklearn.metrics import confusion_matrix
-
+import torch
 
 def init_wandb(model, wandb_api_key, wandb_resume, wandb_name, wandb_project, wandb_run_id, wandb_watch):
     os.environ["WANDB_API_KEY"] = wandb_api_key
@@ -83,7 +83,7 @@ def save_ckp(state, epoch, checkpoint_path, checkpoint_base, wandb):
     state: checkpoint we want to save
     checkpoint_path: path to save checkpoint
     """
-    f_path = checkpoint_path + "Epoch_" + str(epoch) + '.pth'
+    f_path = os.path.join(checkpoint_path, "Epoch_" + str(epoch) + '.pth')
     # save checkpoint data to the path given, checkpoint_path
     torch.save(state, f_path)
     if wandb:
